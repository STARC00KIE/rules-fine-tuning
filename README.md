# 1. 목표
- 문서를 기반으로 해당 도메인 지식을 정확히 이해하는 LLM 모델 파인튜닝 수행

# 2. 개요
- 학습 대상: 취업규칙_브이티더블유_20230829.pdf
- 활용 인프라: 사내 보유 GPU 서버
- 수행 내용
  - PDF 텍스트 추출 및 구조적 전처리
  - 학습용 QA(질문-답변) 데이터셋 구축
  - LoRA 기반 LLM 파인튜닝(Fine-tuning) 및 모델 최적화

# 3. 실행 방안
## 3.1 학습 데이터셋 구축
- 비정형 데이터 구조화: PDF 파싱 툴을 활용하여 텍스트 추출 후 전처리
- 계층적 청킹: PDF 단순 길이 기반 분할 대신 의미론적 분할 수행
## 3.2 QA 데이터셋 생성
- 역발상 엔지니어링: Teacher Model을 활용, 원문을 입력받아 예상 질문 생성
- 질문 유형 다변화:
  - 단순 조회형(200): 숫자, 기간 등 명시적 정보 (예: "경조사 휴가 일수는?")
  - 절차형(200): 신청 방법, 제출 서류 등 프로세스 (예: "육아휴직 신청 절차는?")
  - 부정형(100): 규정에 없는 내용에 대해 "알 수 없음" 답변 유도
## 3.3 학습 전략
- 알고리즘: QLoRA (Quantized Low-Rank Adaptation) 적용 (GPU 메모리 효율화)
- 파운데이션 모델: Qwen3-8B 또는 Llama-3-12B 적용
- 프레임워크: Unsloth 활용 (학습 최적화)
- 프롬프트 엔지니어링:
  - 시스템 프롬프트 앵커링: "VTW의 인사 규정 전문가" 페르소나 부여
  - Loss Masking: 모델의 사용자 답변(Output) 영역만 학습하도록 설정

4. 추진 일정
- 데이터셋 구축 및 생성: 2025. 11. 24. ~ 2025. 11. 28.
- LLM 파인튜닝: 2025. 12. 01. ~ 2025. 12. 05.